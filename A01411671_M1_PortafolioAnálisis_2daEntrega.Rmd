---
title: "A01411671 M1. Portafolio | 2daEntrega"
author: "Miguel Ángel Bermea Rodríguez | A01411671"
date: "2023-09-04"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Momento de Retroalimentación \| M1. Construcción de un modelo estadístico base

# Portafolio Implementación

## Primera entrega

### Finalidad de la entrega

La primera la entregarás al finalizar la semana 3. La finalidad es que entregues un borrador de la versión total de la exploración y preparación de los datos para que te sea retroalimentada. Esta entrega sólo es requisito.

### Descripción

Una empresa automovilística china aspira a entrar en el mercado estadounidense. Desea establecer allí una unidad de fabricación y producir automóviles localmente para competir con sus contrapartes estadounidenses y europeas. Contrataron una empresa de consultoría de automóviles para identificar los principales factores de los que depende el precio de los automóviles, específicamente, en el mercado estadounidense, ya que pueden ser muy diferentes del mercado chino. Esencialmente, la empresa quiere saber:

-   Qué variables son significativas para predecir el precio de un automóvil

-   Qué tan bien describen esas variables el precio de un automóvil

### Lectura de datos

```{r}
# Conjunto de datos de diferentes tipos de automóviles en el mercado estadounidense
df <- read.csv("precios_autos.csv")
head(df)

# Conversión de las variables cualitativas/categóricas a factores
df$symboling <- as.factor(df$symboling)
df$CarName <- as.factor(df$CarName)
df$fueltype <- as.factor(df$fueltype)
df$carbody <- as.factor(df$carbody)
df$drivewheel <- as.factor(df$drivewheel)
df$enginelocation <- as.factor(df$enginelocation)
df$enginetype <- as.factor(df$enginetype)
df$cylindernumber <- as.factor(df$cylindernumber)
```

### Exploración y preparación de la base de datos (Portafolio de Análisis)

#### 1. Exploración de la base de datos

##### 1. Medidas estadísticas apropiadas para las variables cuantitativas y cualitativas

```{r}
# Variables cuantitativas
summary(df[, sapply(df, is.numeric)])
```

```{r}
# Variables cualitativas
summary(df[,sapply(df, is.factor)])
```

##### 2. Exploración usando herramientas de visualización

```{r}
# Variables cuantitativas
## Medidas de posición: cuartiles, outlier (valores atípicos), boxplots

## Análisis de distribución de los datos (Histogramas). 
## Identificar si tiene forma simétrica o asimétrica

## Analiza colinealidad (coeficiente de correlación y diagramas de dispersión)

num_vars <- names(df)[sapply(df, is.numeric)]

# Para cada variable cuantitativa
for (var_name in num_vars) {
  # Selecciona la variable cuantitativa
  var <- df[[var_name]]
  
  # Calcula los cuartiles
  cuartiles <- quantile(var, probs = c(0.25, 0.5, 0.75))
  print(paste("Cuartiles para", var_name))
  print(cuartiles)
  
  # Identifica valores atípicos
  iqr <- IQR(var)
  outliers <- var[var < (cuartiles[1] - 1.5 * iqr) | var > (cuartiles[3] + 1.5 * iqr)]
  print(paste("Valores atípicos para", var_name))
  print(outliers)
  
  # Cambio a la ventana gráfica
  par(mfrow = c(1, 2))
  
  # Crea un gráfico de caja
  boxplot(var, main = paste("Gráfico de caja para", var_name))
  
  # Crea un histograma
  hist(var, main = paste("Histograma para", var_name), xlab = var_name, col = "blue")
  
  # Cambio a la ventana gráfica
  par(mfrow = c(2, 2))
  
  # Crea diagramas de dispersión con otras variables cuantitativas
  for (other_var_name in num_vars) {
    if (other_var_name != var_name) {
      plot(df[[var_name]], df[[other_var_name]], main = "Diagrama de dispersión", 
           xlab = var_name, ylab = other_var_name)
    }
  }
}

# Restablece la ventana gráfica
par(mfrow = c(1, 1))

library(corrplot)
## Matriz de correlación entre variables cuantitativas
corr_matrix <- cor(df[,num_vars])
corrplot(corr_matrix, method = "circle")
```

```{r}
# Variables categóricas
## Distribución de los datos (diagramas de barras, diagramas de pastel)

## Analiza asociación o colinealidad (diagramas de caja 
## y bigote de precio por categoría y barras por categoría)

cat_vars <- names(df)[sapply(df, is.factor)]

for (var_name in cat_vars) {
  # Selecciona la variable categórica
  var <- df[[var_name]]
  
  # Cambio de margen 
  par(mar = c(4.5,4.5,4.5,4.5))
  
  # Divide la ventana gráfica
  par(mfrow = c(1, 2))
  
  # Diagramas de barras
  barplot(table(var), main = paste("Diagrama de barras de", var_name), xlab = var_name, ylab ="Frecuencia")
  
  # Diagramas de pastel
  pie(table(var), main = paste("Diagrama de pastel de", var_name))
  
  # Restablece la ventana gráfica
  par(mfrow = c(1, 1))
}

for (other_var_name in cat_vars) {
  # Selecciona la variable categórica
  other_var <- df[[other_var_name]]
  
  # Diagramas de caja y bigote
  boxplot(df$price ~ other_var, main = paste("Precio por", other_var_name), 
          xlab = other_var_name, ylab = "Precio")
  
  # Diagramas de barras
  barplot(tapply(df$price, other_var, mean), main = paste("Precio promedio por", other_var_name), 
          xlab = other_var_name, ylab = "Precio")
}

```

##### 3. Problemas de calidad de datos (valores faltantes y outliers)

**Valores faltantes por columna**

```{r}
# Valores faltantes por columna
colSums(is.na(df))
```

**Outliers**

En la sección 2. Exploración usando herramientas de visualización:

-   Para las variables cuantitvas se hizo uso de IQR para obtener los outliers y se visualizó con boxplot

-   Para las variables cualitativas también se visualizó con boxplot

##### 4. Selección de variables para el análisis de las características de los automóviles que determinan su precio

\*\* = Tal vez la utilizo

-   enginesize

-   horsepower

-   curbweight

-   carlength

-   carwidth

-   wheelbase

-   cylindernumber\*\*

-   carbody\*\*

#### 2. Preparación de la base de datos

##### 1. Selección de datos a utilizar

-   Maneja datos categóricos: transforma a variables dummy si es necesario.

En caso de que utilice los datos categóricos preseleccionados (cylindernumber y carbody), debo de tener en cuenta esto para manejarlos de la forma adecuada.

```{r}
cylindernumber_dummy <- model.matrix(~ cylindernumber - 1, data = df)
carbody_dummy <- model.matrix(~ carbody - 1, data = df)
```

```{r}
head(cylindernumber_dummy)
```

```{r}
head(carbody_dummy)
```

En caso de que solo utilice datos cuantitativos, no debo de preocuparme.

-   Maneja apropiadamente datos atípicos.

    -   Identificación: Ya identifique los datos atípicos mediante IQR y se pueden visualizar con los boxplots.

    -   Contexto: La existencia de estos datos se debe a ser datos válidos pero poco comunes

    -   Decisión: Si bien aún no tengo la certeza, si que he identificado posibles alternativas para manejar estos datos

        ```         
        1) Eliminarlos: En caso de que los considere no representativos, 
        puedo optar por eliminarlos. Cabe recalcar que debo estar seguro 
        ya que podría afectar la integridad de mis resultados.

        2) Transformar los datos (va de la mano con lo último de esta entrega): 
        En algunos casos podría aplicar transformaciones matemáticas a mis datos 
        para reducir el impacto de los valores atípicos.

        3) Tratarlos por separado: Puedo analizarlos por separado para entender 
        mejor su naturaleza y posible impactos en mis resultados.
        ```

        Actualmente me decanto más por tratarlos por separado.

##### 2. Transformación de datos a utilizar (en caso de ser necesario)

-   Revisa si es necesario discretizar los datos

En caso de ser necesario, tengo pensado hacer uso de la función *cut* en R para dividir una variable numérica en intervalos y asignar cada observación a uno de esos intervalos.

-   Revisa si es necesario escalar y normalizar los datos

En caso de ser necesario, tengo pensado hacer uso de la función *scale* en R para estandarizar una variable numérica restando su media y dividiendo por su desviación estándar.

*Destacar que la transformación de datos dependerá del modelo a utilizar (lo cual entra en Modelación y verificación del modelo (Portafolio de implementación), ya que es aqui donde buscaré el mejor modelo predictivo para la variable precio)*

## Segunda entrega

### Finalidad de la entrega

Se entregará al finalizar la semana 4. La finalidad es que entregues un borrador de la versión total de la modelación y verificación del modelo (solución final) para que te sea retroalimentada. Esta entrega también es sólo requisito.

### Regresión lineal múltiple y Pruebas de hipótesis

La regresión lineal múltiple es una herramienta estadística útil para analizar la relación entre una variable dependiente y varias variables independientes. 

En el contexto de la situación problema, la regresión lineal múltiple puede utilizarse para predecir el precio de un automóvil en función de sus características (variables seleccionadas). Esta herramienta me permite identificar qué variables son significativas para predecir el precio del automóvil y cuantificar su efecto sobre el precio.

Por otro lado, las pruebas de hipótesis pueden utilizarse para verificar si se cumplen los supuestos de un modelo de regresión lineal múltiple, como la normalidad y la homocedasticidad de los residuos. Esto me permite validar el modelo y asegurarme de que las predicciones sean confiables.

```{r}
model <- lm(price ~ enginesize + horsepower + curbweight + carlength + carwidth + wheelbase, 
            data = df)

summary(model)
```
#### Validación del modelo


**Coeficiente de determinación**

```{r}
rsq <- summary(model)$r.squared
rsq
```
El coeficiente de determinación o R-cuadrado, es una medida que representa que tan bien la línea de regresión se ajusta a los datos, es decir, la bondad de ajuste del modelo.

En este caso, el valor de R-cuadrado es 0.8210592, lo que significa que aproximadamente el 82.1% de la variación en la variable dependiente (precio del automóvil) puede ser explicada por las variables independientes seleccionadas para el modelo.

Cabe recalcar que las variables *enginesize, horsepower* y *carwidth* son las más significativas para predecir el precio del automóvil, ya que tienen p-values bajos (menores que 0.05).

```{r}
library(ggplot2)

data <- data.frame(R_squared = c(rsq))

ggplot(data, aes(x = "", y = R_squared)) +
  geom_bar(stat = "identity") +
  ylim(0, 1) +
  labs(x = "", y = "R-squared") +
  theme(axis.text.x = element_blank())
```
El gráfico muestra una barra que representa el valor del R-cuadrado y tiene un eje y que va desde 0 hasta 1. 
Esto permite ver qué tan cerca está el modelo de explicar completamente la variabilidad en la variable dependiente.

**Normalidad de los residuos**

(1) Hipótesis de normalidad

-   H0: Los residuos siguen una distribución normal.

-   Ha: Los residuos no siguen una distribución normal.

(2) Regla de decisión

Se utilizará la prueba de Anderson-Darling para evaluar la normalidad de los residuos.

Si el p-value es menor que el nivel de significancia (por ejemplo, 0.05), rechazamos la hipótesis nula y concluimos que los residuos no siguen una distribución normal.

(3) Análisis del resultado

```{r}
library(nortest)

ad.test(model$residuals)
```
(4) Conclusión

El p-value es 3.684e-06, lo que es muy bajo. Esto indica que los residuos del modelo no siguen una distribución normal y, por lo tanto, se rechaza la hipótesis nula de normalidad. Esto sugiere que podría ser necesario revisar el modelo y considerar la posibilidad de transformar las variables o utilizar un modelo diferente para ajustar los datos.

**Verificación de media cero**

(1) Hipótesis de media cero

-   H0: La media de los residuos es igual a 0.

-   H1: La media de los residuos no es igual a 0.

(2) Regla de decisión

Se utilizará la prueba t de una muestra aplicada a los residuos del modelo para determinar si la media es igual a un valor específico.

El p-value indica si la media de los residuos es igual a 0. Un p-value bajo (menor que 0.05) indica que la media de los residuos no es igual a 0 y, por lo tanto, se rechaza la hipótesis nula.

(3) Análisis del resultado

```{r}
t_test <- t.test(model$residuals)
t_test
```
```{r}
library(ggplot2)

data <- data.frame(
  Variable = "Residuals",
  `LowerBound` = t_test$conf.int[1],
  `UpperBound` = t_test$conf.int[2]
)

ggplot(data, aes(x = Variable, ymin = `LowerBound`, ymax = `UpperBound`)) +
  geom_errorbar(width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "", y = "Confidence Interval") +
  theme(axis.text.x = element_blank())
```
La línea punteada que representa la hipótesis nula (media igual a 0) se encuentra dentro del intervalo de confianza del 95% para la 
media de los residuos, esto indica que no hay evidencia suficiente para rechazar la hipótesis nula. 
En otras palabras, no hay evidencia suficiente para afirmar que la media de los residuos no es igual a 0.

(4) Conclusión

En este caso, el p-value es 1, lo que es muy alto. Esto indica que no hay evidencia suficiente para rechazar 
la hipótesis nula de que la media de los residuos es igual a 0. Esto sugiere que el modelo está bien especificado y que 
no hay sesgo en las predicciones.

**Homocedasticidad**

(1) Hipótesis de prueba de Breusch-Pagan

-   H0: No hay heterocedasticidad en el modelo, la varianza de los residuos es constante.

-   Ha: Hay heterocedasticidad en el modelo, la varianza de los residuos no es constante.

(2) Regla de decisión

Para verificar si se cumple el supuesto de homocedasticidad en el modelo, se utilizará la prueba de Breusch-Pagan. 
Esta prueba se utiliza para determinar si hay evidencia de heterocedasticidad (es decir, si la varianza de los residuos no es constante) 
en un modelo de regresión lineal múltiple.

Si el p-value es menor que el nivel de significancia (por ejemplo, 0.05), se rechaza la hipótesis nula y se concluye que hay evidencia suficiente para afirmar que hay heterocedasticidad en el modelo.

(3) Análisis del resultado

Se grafican los residuos para observar tendencia:

```{r}
plot(model$fitted.values, model$residuals)
abline(h=0, col='blue')
```
Se utiliza prueba de Breusch-Pagan:

```{r}
library(lmtest)
library(zoo)

bp_test <- bptest(model)
bp_test
```

(4) Conclusión

En este caso, el p-value es 4.209e-14, lo que es muy bajo. Esto indica que hay evidencia suficiente para rechazar la 
hipótesis nula y concluir que hay heterocedasticidad en el modelo. Esto sugiere que podría ser necesario revisar el modelo y considerar la posibilidad de transformar las variables o utilizar técnicas como la regresión ponderada para corregir este problema.

### Conclusión del análisis

En base a los resultados de mi análisis, se puede concluir que el modelo de regresión lineal múltiple que ajusté para predecir el precio de un automóvil en función de la variables seleccionadas tiene un buen ajuste. El valor del coeficiente de determinación (R-cuadrado) es 0.8210592, lo que significa que aproximadamente el 82.1% de la variación en el precio del automóvil puede ser explicada por las variables independientes seleccionadas para el modelo. Además, las variables *enginesize, horsepower* y *carwidth* son significativas para predecir el precio del automóvil, ya que tienen p-values bajos.

Sin embargo, también se encontró evidencia de heterocedasticidad en el modelo, lo que indica que la varianza de los residuos no es constante. Esto sugiere que podría ser necesario revisar el modelo y considerar la posibilidad de transformar las variables o utilizar técnicas como la regresión ponderada para corregir este problema.

En resumen, mi análisis muestra que el modelo de regresión lineal múltiple que ajusté tiene un buen ajuste y que las variables *enginesize, horsepower* y *carwidth* son significativas para predecir el precio del automóvil. Sin embargo, también se encontró evidencia de heterocedasticidad en el modelo, lo que sugiere que podría ser necesario revisarlo y la posibilidad de considerar otras variables que reemplacen a las que no fueron tan significativas, transformar las variables o utilizar técnicas para corregir este problema.
